{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxy6-x7QdPqH",
        "outputId": "2f2df1d8-a321-4f33-a341-e81b5191f337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "selamat pagi\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Contoh penggunaan\n",
        "sample_text = \"selamat pagi\"\n",
        "print(remove_punctuation(sample_text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N16eY9z8dRb-",
        "outputId": "a1605e4a-e0c9-4f75-e028-ac33a5053e0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are  apples and  oranges.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def remove_numbers(text):\n",
        "    return re.sub(r'\\d+', '', text)\n",
        "\n",
        "# Contoh penggunaan\n",
        "sample_text = \"There are 2 apples and 10 oranges.\"\n",
        "print(remove_numbers(sample_text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxnsvveNYxJJ",
        "outputId": "80fbca31-44da-4637-e704-fd78aa08a62b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "selamat pagi.\n"
          ]
        }
      ],
      "source": [
        "def to_lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "# Contoh penggunaan\n",
        "sample_text = \"selamat pagi.\"\n",
        "print(to_lowercase(sample_text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cJIwqE-dc1A",
        "outputId": "2ce5f1e2-5999-4b20-8866-ca4ea73397af"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'nltk'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      4\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt_tab\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
          ]
        }
      ],
      "source": [
        "from 'nltk'.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def tokenize(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Contoh penggunaan\n",
        "sample_text = \"This is an example sentence.\"\n",
        "print(tokenize(sample_text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcbsxqv8etEQ",
        "outputId": "74cb3594-4918-4a3e-9fc1-ffeb545279cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['This', 'example', 'showing', 'stopwords', 'removal', '.']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return [word for word in words if word not in stop_words]\n",
        "\n",
        "# Contoh penggunaan\n",
        "sample_text = \"This is an example showing stopwords removal.\"\n",
        "tokenized_text = tokenize(sample_text)\n",
        "print(remove_stopwords(tokenized_text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBkU5DCgfOZc",
        "outputId": "64bb3275-a533-43f8-cdfd-2889459e3b3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['thi', 'exampl', 'show', 'stem', 'word', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "def stem_words(words):\n",
        "    ps = PorterStemmer()\n",
        "    return [ps.stem(word) for word in words]\n",
        "\n",
        "# Contoh penggunaan\n",
        "sample_text = \"This is an example showing stemming of words.\"\n",
        "tokenized_text = tokenize(sample_text)\n",
        "filtered_words = remove_stopwords(tokenized_text)\n",
        "print(stem_words(filtered_words))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8n5VQsUgWXp"
      },
      "outputs": [],
      "source": [
        "sentence1 = \"I love football\"\n",
        "sentence2 = \"Messi is a great football player\"\n",
        "sentence3 = \"Messi has won seven Ballon d’Or awards \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcb96JN0goyX",
        "outputId": "77d2a391-1a26-4529-bc6c-2e8a2d5551de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I love football', 'Messi is a great football player', 'Messi has won seven Ballon d’Or awards ']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "docs = [sentence1, sentence2, sentence3]\n",
        "print(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "qncwNZRXg1l1",
        "outputId": "ea10bb61-9f0b-4c8a-af21-9d8695cf8735"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"awards\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ballon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"football\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"great\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"love\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"messi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"or\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"player\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seven\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"won\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0198ae79-e012-43d0-95fc-5114041e9c2c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>awards</th>\n",
              "      <th>ballon</th>\n",
              "      <th>football</th>\n",
              "      <th>great</th>\n",
              "      <th>has</th>\n",
              "      <th>is</th>\n",
              "      <th>love</th>\n",
              "      <th>messi</th>\n",
              "      <th>or</th>\n",
              "      <th>player</th>\n",
              "      <th>seven</th>\n",
              "      <th>won</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0198ae79-e012-43d0-95fc-5114041e9c2c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0198ae79-e012-43d0-95fc-5114041e9c2c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0198ae79-e012-43d0-95fc-5114041e9c2c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2b4c9d23-29d6-4635-b120-9dd037f1315c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b4c9d23-29d6-4635-b120-9dd037f1315c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2b4c9d23-29d6-4635-b120-9dd037f1315c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   awards  ballon  football  great  has  is  love  messi  or  player  seven  \\\n",
              "0       0       0         1      0    0   0     1      0   0       0      0   \n",
              "1       0       0         1      1    0   1     0      1   0       1      0   \n",
              "2       1       1         0      0    1   0     0      1   1       0      1   \n",
              "\n",
              "   won  \n",
              "0    0  \n",
              "1    0  \n",
              "2    1  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Mendefinisikan dan menyesuaikan count vectorizer pada dokumen.\n",
        "\n",
        "vec = CountVectorizer()\n",
        "X = vec.fit_transform(docs)\n",
        "#Mengonversi vektor pada DataFrame menggunakan pandas\n",
        "\n",
        "df = pd.DataFrame(X.toarray(),\n",
        "    columns=vec.get_feature_names_out())\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN06ffX_M49M",
        "outputId": "6d7b7d93-af75-418e-c552-f48771293be7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Term Frequency (TF):\n",
            "Document 1 TF:\n",
            "    the: 0.2222\n",
            "    quick: 0.1111\n",
            "    brown: 0.1111\n",
            "    fox: 0.1111\n",
            "    jumps: 0.1111\n",
            "    over: 0.1111\n",
            "    lazy: 0.1111\n",
            "    dog: 0.1111\n",
            "Document 2 TF:\n",
            "    the: 0.2857\n",
            "    lazy: 0.1429\n",
            "    dog: 0.1429\n",
            "    sleeps: 0.1429\n",
            "    in: 0.1429\n",
            "    sun: 0.1429\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "from math import log\n",
        "\n",
        "# Tiga dokumen dalam korpus\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog\",\n",
        "    \"The lazy dog sleeps in the sun\"\n",
        "    ]\n",
        "\n",
        "# Preprocessing: Lowercasing and tokenizing\n",
        "tokenized_documents = [doc.lower().split() for doc in documents]\n",
        "\n",
        "# Menghitung TF\n",
        "def compute_tf(tokenized_doc):\n",
        "    tf_dict = {}\n",
        "    term_count = Counter(tokenized_doc)\n",
        "    total_terms = len(tokenized_doc)\n",
        "    for term, count in term_count.items():\n",
        "        tf_dict[term] = count / total_terms\n",
        "    return tf_dict\n",
        "\n",
        "tf_list = [compute_tf(doc) for doc in tokenized_documents]\n",
        "\n",
        "print(\"Term Frequency (TF):\")\n",
        "for idx, tf in enumerate(tf_list):\n",
        "    print(f\"Document {idx + 1} TF:\")\n",
        "    for term, score in tf.items():\n",
        "        print(f\"    {term}: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGpZKYNgO-Ed",
        "outputId": "b42539dc-462c-4629-dc97-8a4dcc96384b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inverse Document Frequency (IDF):\n",
            "    brown: 1.0000\n",
            "    lazy: 0.5945\n",
            "    fox: 1.0000\n",
            "    quick: 1.0000\n",
            "    in: 1.0000\n",
            "    sleeps: 1.0000\n",
            "    the: 0.5945\n",
            "    dog: 0.5945\n",
            "    sun: 1.0000\n",
            "    jumps: 1.0000\n",
            "    over: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Menghitung IDF\n",
        "def compute_idf(tokenized_docs):\n",
        "    idf_dict = {}\n",
        "    total_docs = len(tokenized_docs)\n",
        "    all_terms = set(term for doc in tokenized_docs for term in doc)\n",
        "    for term in all_terms:\n",
        "        doc_containing_term = sum(1 for doc in tokenized_docs if term in doc)\n",
        "        idf_dict[term] = log(total_docs / (1 + doc_containing_term)) + 1\n",
        "    return idf_dict\n",
        "\n",
        "idf_dict = compute_idf(tokenized_documents)\n",
        "\n",
        "print(\"\\nInverse Document Frequency (IDF):\")\n",
        "for term, score in idf_dict.items():\n",
        "    print(f\"    {term}: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w36ZT0myY6-a",
        "outputId": "1c23604b-9d64-452d-a691-2860cfbf565b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "TF-IDF:\n",
            "Document 1 TF-IDF:\n",
            "    the: 0.1321\n",
            "    quick: 0.1111\n",
            "    brown: 0.1111\n",
            "    fox: 0.1111\n",
            "    jumps: 0.1111\n",
            "    over: 0.1111\n",
            "    lazy: 0.0661\n",
            "    dog: 0.0661\n",
            "Document 2 TF-IDF:\n",
            "    the: 0.1699\n",
            "    lazy: 0.0849\n",
            "    dog: 0.0849\n",
            "    sleeps: 0.1429\n",
            "    in: 0.1429\n",
            "    sun: 0.1429\n"
          ]
        }
      ],
      "source": [
        "# Menghitung TF-IDF\n",
        "def compute_tfidf(tf_list, idf_dict):\n",
        "    tfidf_list = []\n",
        "    for tf in tf_list:\n",
        "        tfidf_dict = {}\n",
        "        for term, tf_value in tf.items():\n",
        "            tfidf_dict[term] = tf_value * idf_dict.get(term, 0)\n",
        "        tfidf_list.append(tfidf_dict)\n",
        "    return tfidf_list\n",
        "\n",
        "tfidf_list = compute_tfidf(tf_list, idf_dict)\n",
        "\n",
        "print(\"\\nTF-IDF:\")\n",
        "for idx, tfidf in enumerate(tfidf_list):\n",
        "    print(f\"Document {idx + 1} TF-IDF:\")\n",
        "    for term, score in tfidf.items():\n",
        "        print(f\"    {term}: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqqro1ifEA1H",
        "outputId": "e64276b1-d8fd-44b7-b9c9-114c76b319a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g4KJeGi1jt-k",
        "outputId": "c41c5554-3fb2-4f28-8aae-944682c14e8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Found existing installation: gensim 4.3.3\n",
            "Uninstalling gensim-4.3.3:\n",
            "  Successfully uninstalled gensim-4.3.3\n",
            "Found existing installation: pandas 2.2.3\n",
            "Uninstalling pandas-2.2.3:\n",
            "  Successfully uninstalled pandas-2.2.3\n",
            "Found existing installation: scikit-learn 1.6.1\n",
            "Uninstalling scikit-learn-1.6.1:\n",
            "  Successfully uninstalled scikit-learn-1.6.1\n",
            "Found existing installation: nltk 3.9.1\n",
            "Uninstalling nltk-3.9.1:\n",
            "  Successfully uninstalled nltk-3.9.1\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting nltk\n",
            "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Using cached scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "Installing collected packages: numpy, nltk, pandas, scikit-learn, gensim\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 nltk-3.9.1 numpy-1.26.4 pandas-2.2.3 scikit-learn-1.6.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "62f6cef0626e4c8db9937f8eb37aeff6",
              "pip_warning": {
                "packages": [
                  "gensim",
                  "nltk"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([-4.6599745e-03,  3.9806510e-03,  1.9114142e-03,  5.6526200e-03,\n",
            "        3.1190130e-03, -7.5333443e-04,  3.4238021e-03,  3.3095828e-03,\n",
            "       -5.7439799e-03,  1.2399314e-04,  1.5154898e-03, -4.6827844e-03,\n",
            "        2.2198728e-03,  2.7434174e-03,  3.8831220e-03,  4.2578860e-05,\n",
            "        2.1247193e-03,  4.1170805e-03, -6.9772042e-03, -4.5314594e-03,\n",
            "        9.0925070e-04,  1.2928164e-03,  5.1809270e-03, -6.0568438e-03,\n",
            "        6.1365720e-03, -7.6482916e-04,  1.3757148e-05,  1.5500397e-03,\n",
            "       -3.6960281e-03, -3.5813847e-04,  3.5609016e-03, -4.6297759e-03,\n",
            "        1.7671251e-03, -1.4140781e-03, -1.8171680e-03,  9.4895152e-04,\n",
            "        3.1889200e-03,  2.7076614e-03,  3.7414092e-03, -1.3430156e-03,\n",
            "       -2.4245111e-03,  8.4423088e-04, -4.7280975e-03,  2.1121051e-04,\n",
            "       -5.4197269e-05,  2.6140013e-03,  7.9148129e-05,  2.3835800e-03,\n",
            "       -5.3164572e-04,  1.5393719e-03,  2.6096610e-04, -1.8477604e-03,\n",
            "       -2.8962991e-03, -2.0742700e-03,  6.8781583e-04, -1.0468734e-03,\n",
            "        3.4460998e-03, -9.7695051e-04, -1.1877757e-03,  1.6373022e-03,\n",
            "       -3.1596348e-03, -1.1717058e-03,  2.2588442e-03, -3.2073832e-03,\n",
            "       -3.6474881e-03,  4.1822228e-03,  2.5159442e-03,  2.8151290e-03,\n",
            "       -2.9355369e-03,  4.3918104e-03, -8.7443623e-04,  1.5088705e-03,\n",
            "        3.5597067e-03,  1.6596788e-03, -1.8021559e-03, -9.5931231e-04,\n",
            "        7.8243064e-04, -1.8590200e-03, -2.4578089e-03, -3.6341541e-03,\n",
            "       -2.4609328e-03, -2.2653057e-03,  2.2122499e-03,  3.7817418e-04,\n",
            "        6.4289779e-04, -1.1216429e-03,  5.4433977e-04, -7.3489407e-03,\n",
            "        1.4341753e-03,  1.6224750e-03, -1.7188978e-03,  1.3615468e-03,\n",
            "        4.4334223e-03, -3.3250079e-03,  6.1996551e-03,  5.3622178e-03,\n",
            "        1.1810204e-03, -4.5055989e-04,  1.3739709e-03, -4.2531115e-04],\n",
            "      dtype=float32), array([-1.9313125e-03,  9.3046331e-04,  3.0773730e-04,  1.0126045e-03,\n",
            "       -7.5734127e-04, -1.2401232e-03,  2.8874916e-03,  4.2693545e-03,\n",
            "       -5.1834537e-03, -2.4230410e-03,  6.4616912e-04, -2.7678537e-03,\n",
            "       -1.7599637e-03,  2.8523814e-03, -3.3636615e-04, -1.9731321e-03,\n",
            "        3.5947736e-03,  3.9047871e-03, -4.2746086e-03, -5.1471749e-03,\n",
            "       -1.0425894e-03, -1.4669753e-03,  5.7777213e-03, -1.7462283e-03,\n",
            "        3.0710169e-03, -1.3190617e-03,  7.6538522e-04,  1.7179493e-04,\n",
            "       -2.8204739e-03,  2.2486877e-03,  4.0541538e-03, -2.5083921e-03,\n",
            "       -7.3176745e-04, -4.1306363e-03, -2.6340741e-03,  2.0460545e-03,\n",
            "        2.7224307e-03, -3.1366944e-05,  2.0372800e-03, -1.7122261e-03,\n",
            "        1.9060476e-03, -2.6760600e-03, -3.5613715e-03, -1.4925643e-03,\n",
            "        6.9635280e-04,  3.7173007e-03, -1.7332789e-03,  5.8259803e-04,\n",
            "       -5.8009132e-04,  1.1366077e-03,  7.1395829e-04, -4.9702097e-03,\n",
            "       -2.4356288e-03,  1.5649481e-03, -3.8705268e-03, -1.7277289e-03,\n",
            "        3.8490728e-03, -4.1743871e-03, -4.9488698e-03, -5.4921571e-04,\n",
            "        4.5435317e-04, -1.0912399e-03,  3.0742262e-03, -3.5737418e-03,\n",
            "       -9.5182017e-04,  5.2035893e-03,  1.8484255e-03,  5.8638875e-04,\n",
            "       -3.3670131e-03,  2.0265747e-04,  1.2600668e-03,  3.4847558e-03,\n",
            "        2.6909849e-03,  1.9792460e-03,  1.3079892e-03,  6.1164657e-04,\n",
            "        1.0393398e-03,  2.0030744e-03, -6.0397526e-04, -3.8577066e-04,\n",
            "        9.0077298e-04, -2.9947348e-03,  1.7637844e-04, -1.3180377e-03,\n",
            "       -1.1371106e-03, -4.1426606e-03,  1.1577058e-03, -3.5737106e-03,\n",
            "       -9.9799785e-05,  9.9267240e-04,  9.1591495e-04,  2.7395862e-03,\n",
            "        6.2088633e-04, -3.0390630e-03,  4.8088627e-03,  3.8052977e-03,\n",
            "        1.7830289e-03, -4.6698428e-03,  1.8128687e-04,  5.5501639e-04],\n",
            "      dtype=float32), array([-0.00432601,  0.00406971,  0.00082073,  0.00285212,  0.00260905,\n",
            "       -0.00250835,  0.00165858,  0.00615073, -0.0025268 , -0.00281055,\n",
            "        0.00292883, -0.00209868,  0.00078521,  0.00207212,  0.00361077,\n",
            "       -0.00070364,  0.00591563,  0.00327086, -0.0071653 , -0.00208044,\n",
            "        0.00106662, -0.00162748,  0.00522037, -0.00203441,  0.00282427,\n",
            "       -0.00070741,  0.00217527,  0.00482545, -0.00344711,  0.00179091,\n",
            "        0.00214926, -0.00413491, -0.0014018 , -0.00439473, -0.00079619,\n",
            "        0.0020215 ,  0.00595606, -0.00062651,  0.00040572,  0.00335066,\n",
            "       -0.00096744,  0.00122857, -0.00313262, -0.00018954,  0.00204034,\n",
            "        0.00373947,  0.00064566,  0.00074721, -0.00025051,  0.00190524,\n",
            "        0.00134328, -0.00189608, -0.00525017, -0.00329428, -0.00192758,\n",
            "       -0.00053604,  0.00341957,  0.00121441, -0.00128411,  0.00227522,\n",
            "       -0.00138613,  0.00118845,  0.00182446, -0.00309547, -0.00020932,\n",
            "        0.00286489,  0.00342713,  0.00334012, -0.00112963,  0.0012612 ,\n",
            "        0.00288359,  0.00021396,  0.00175419,  0.00230547, -0.00046088,\n",
            "       -0.00063532,  0.00115969,  0.00186579, -0.00151026, -0.00257436,\n",
            "       -0.00356586,  0.00107892,  0.00160482,  0.00074986, -0.00118709,\n",
            "       -0.00217638,  0.00259523, -0.00420296,  0.00143771, -0.00182537,\n",
            "       -0.00230408,  0.00081291,  0.00351384, -0.00358164,  0.00613726,\n",
            "        0.00316018,  0.00204554, -0.00409202, -0.00072541, -0.00041762],\n",
            "      dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "# Uninstall the potentially conflicting libraries\n",
        "!pip uninstall -y numpy gensim pandas scikit-learn nltk\n",
        "\n",
        "# Reinstall the libraries. Pip will automatically try to find compatible versions.\n",
        "!pip install numpy gensim pandas scikit-learn nltk\n",
        "\n",
        "# Now try importing gensim again\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "corpus = [\n",
        "    'Ini adalah dokumen pertama.',\n",
        "    'Dokumen kedua ini adalah contoh.',\n",
        "    'Dan ini adalah dokumen ketiga.'\n",
        "]\n",
        "\n",
        "sentences = [doc.split() for doc in corpus]\n",
        "\n",
        "# It's good practice to check if the corpus is not empty and contains lists of tokens\n",
        "if sentences and all(isinstance(s, list) and s for s in sentences):\n",
        "    model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "    def document_vector(doc):\n",
        "        # Ensure words exist in the model's vocabulary\n",
        "        # Preprocess the input document for consistency with how the model was trained\n",
        "        processed_doc = doc.lower() # Assuming the model was trained on lowercased text\n",
        "        words_in_vocab = [word for word in processed_doc.split() if word in model.wv]\n",
        "        if not words_in_vocab:\n",
        "            # Handle cases where no words in the document are in the vocabulary\n",
        "            # Returning a vector of NaNs might be preferable for clearer debugging\n",
        "            # but a zero vector is common.\n",
        "            return np.zeros(model.vector_size)\n",
        "        return np.mean([model.wv[word] for word in words_in_vocab], axis=0)\n",
        "\n",
        "    doc_vectors = [document_vector(doc) for doc in corpus]\n",
        "    print(doc_vectors)\n",
        "else:\n",
        "    print(\"Corpus is empty or not correctly formatted after splitting.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohgoXHT4v5Nn",
        "outputId": "ed37bbed-19c3-4e04-f5ba-f36e9ba972b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G6TqUQzwYrq"
      },
      "source": [
        "Klasifikasi teks dengan Machine Learning.\n",
        "This dataset is a collection newsgroup documents. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-IzwLWVwAih",
        "outputId": "af104a3d-bf4a-4e91-a605-a75ad28def66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8425297113752123\n",
            "Classification Report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alt.atheism       0.88      0.72      0.79       198\n",
            "           comp.graphics       0.86      0.79      0.82       245\n",
            " comp.os.ms-windows.misc       0.88      0.83      0.85       242\n",
            "comp.sys.ibm.pc.hardware       0.66      0.86      0.75       238\n",
            "   comp.sys.mac.hardware       0.95      0.84      0.89       250\n",
            "          comp.windows.x       0.96      0.80      0.87       260\n",
            "            misc.forsale       0.96      0.66      0.78       241\n",
            "               rec.autos       0.89      0.93      0.91       244\n",
            "         rec.motorcycles       0.91      0.95      0.93       219\n",
            "      rec.sport.baseball       0.96      0.94      0.95       261\n",
            "        rec.sport.hockey       0.90      0.98      0.94       245\n",
            "               sci.crypt       0.78      0.98      0.87       251\n",
            "         sci.electronics       0.92      0.80      0.86       249\n",
            "                 sci.med       0.97      0.88      0.92       249\n",
            "               sci.space       0.88      0.98      0.93       240\n",
            "  soc.religion.christian       0.49      0.99      0.66       245\n",
            "      talk.politics.guns       0.78      0.96      0.86       230\n",
            "   talk.politics.mideast       0.93      0.97      0.95       234\n",
            "      talk.politics.misc       1.00      0.57      0.73       207\n",
            "      talk.religion.misc       1.00      0.16      0.28       164\n",
            "\n",
            "                accuracy                           0.84      4712\n",
            "               macro avg       0.88      0.83      0.83      4712\n",
            "            weighted avg       0.88      0.84      0.84      4712\n",
            "\n",
            "Confusion Matrix:\n",
            "[[143   0   0   0   0   0   0   0   0   0   0   0   0   0   2  49   1   3\n",
            "    0   0]\n",
            " [  0 193   4  12   0   5   1   2   2   0   0   7   0   0   3  14   0   2\n",
            "    0   0]\n",
            " [  0   5 200  24   1   2   0   2   0   0   0   2   1   0   2   3   0   0\n",
            "    0   0]\n",
            " [  0   5   8 205   7   0   0   1   0   1   2   2   4   0   0   3   0   0\n",
            "    0   0]\n",
            " [  0   1   4  16 209   1   0   2   1   0   3   7   2   0   2   2   0   0\n",
            "    0   0]\n",
            " [  1  13   5   8   1 207   0   0   5   1   2   5   0   0   6   5   1   0\n",
            "    0   0]\n",
            " [  0   0   2  31   2   0 158  12   5   1   2  11   5   1   2   7   1   1\n",
            "    0   0]\n",
            " [  0   2   0   0   0   0   2 226   1   0   1   2   2   1   0   5   2   0\n",
            "    0   0]\n",
            " [  0   0   0   1   0   0   3   3 208   0   0   0   0   0   0   2   2   0\n",
            "    0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 246  10   0   0   0   1   3   0   1\n",
            "    0   0]\n",
            " [  0   0   0   1   0   0   0   1   2   0 240   0   0   0   0   1   0   0\n",
            "    0   0]\n",
            " [  0   1   2   0   0   0   0   0   0   0   0 245   0   0   0   3   0   0\n",
            "    0   0]\n",
            " [  0   3   0  11   0   0   1   5   1   2   2  15 200   1   5   3   0   0\n",
            "    0   0]\n",
            " [  0   0   0   0   0   0   0   1   1   1   0   6   3 218   3  13   3   0\n",
            "    0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   2 235   2   0   0\n",
            "    0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0 243   0   1\n",
            "    0   0]\n",
            " [  0   0   1   0   0   0   0   0   0   0   0   4   0   0   0   4 221   0\n",
            "    0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   5   0 228\n",
            "    0   0]\n",
            " [  0   0   0   0   0   0   0   0   1   1   1   4   0   2   6  25  41   8\n",
            "  118   0]\n",
            " [ 17   0   0   0   0   0   0   0   2   2   3   2   0   0   0 100  10   1\n",
            "    0  27]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "# 1. Mengumpulkan data\n",
        "newsgroups = fetch_20newsgroups(subset='all')\n",
        "\n",
        "# 2. Preprocessing data\n",
        "# Tidak perlu preprocessing khusus karena kita akan menggunakan TfidfVectorizer\n",
        "\n",
        "# 3. Membagi data menjadi training dan testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(newsgroups.data, newsgroups.target, test_size=0.25, random_state=42)\n",
        "\n",
        "# 4. Melatih model\n",
        "# Membuat pipeline yang mencakup TfidfVectorizer dan MultinomialNB\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "\n",
        "# Melatih model menggunakan training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Mengevaluasi model\n",
        "# Prediksi pada testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluasi kinerja model\n",
        "print(f\"Accuracy: {metrics.accuracy_score(y_test, y_pred)}\")\n",
        "print(\"Classification Report:\")\n",
        "print(metrics.classification_report(y_test, y_pred, target_names=newsgroups.target_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
